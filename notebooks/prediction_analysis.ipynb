{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileFolder = \"normalized_val_test_results/\"\n",
    "filePaths = [\"normalized_val_true_label.txt\",\"normalized_val_predicted_label.txt\",\n",
    "             \"normalized_val_predicted_score.txt\",\"normalized_val_file_paths.txt\"]\n",
    "files = []\n",
    "\n",
    "for file in filePaths:\n",
    "    file = fileFolder + file\n",
    "    files.append(open(file, 'r').readlines())\n",
    "    \n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(zip(*files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "\n",
    "for true, predict, score, path in files:\n",
    "    true = int(true)\n",
    "    predict = int(predict)\n",
    "    if true == 0:\n",
    "        true = \"female\"\n",
    "    else:\n",
    "        true = \"male\"\n",
    "    if predict == 0:\n",
    "        predict = \"female\"\n",
    "    else:\n",
    "        predict = \"male\"\n",
    "        \n",
    "    score = float(score)\n",
    "    \n",
    "    path = path[26:-1]\n",
    "    \n",
    "    values.append((true, predict, score, path))\n",
    "\n",
    "df = pd.DataFrame.from_records(values, columns=[\"True Label\", \"Predicted Label\", \"Prediction Score\", \"Filepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Prediction Score'], ascending=False, inplace=True)\n",
    "\n",
    "top_m = df[(df['Prediction Score'] <= 5) & (df['True Label'] == df['Predicted Label']) & (df['True Label'] == 'male')].head(50).values.tolist()\n",
    "top_f = df[(df['Prediction Score'] <= 5) & (df['True Label'] == df['Predicted Label']) & (df['True Label'] == 'female')].head(50).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/normalized/val/male/2176159_21016_0_0.png',\n",
       "  '/normalized/val/male/2275320_21015_0_0.png',\n",
       "  '/normalized/val/male/3713247_21015_0_0.png',\n",
       "  '/normalized/val/male/1132451_21016_0_0.png',\n",
       "  '/normalized/val/male/4396854_21016_0_0.png',\n",
       "  '/normalized/val/male/4429701_21015_0_0.png',\n",
       "  '/normalized/val/male/4318435_21015_0_0.png',\n",
       "  '/normalized/val/male/3405207_21016_0_0.png',\n",
       "  '/normalized/val/male/5765892_21016_0_0.png',\n",
       "  '/normalized/val/male/1697619_21016_0_0.png',\n",
       "  '/normalized/val/male/1381053_21015_0_0.png',\n",
       "  '/normalized/val/male/2489752_21015_0_0.png',\n",
       "  '/normalized/val/male/4145029_21016_1_0.png',\n",
       "  '/normalized/val/male/1130348_21016_0_0.png',\n",
       "  '/normalized/val/male/5153478_21015_1_0.png',\n",
       "  '/normalized/val/male/5921747_21015_0_0.png',\n",
       "  '/normalized/val/male/1489150_21016_0_0.png',\n",
       "  '/normalized/val/male/5874816_21015_0_0.png',\n",
       "  '/normalized/val/male/4824537_21016_0_0.png',\n",
       "  '/normalized/val/male/4727320_21015_0_0.png',\n",
       "  '/normalized/val/male/3744362_21015_0_0.png',\n",
       "  '/normalized/val/male/1349742_21016_0_0.png',\n",
       "  '/normalized/val/male/2489752_21015_1_0.png',\n",
       "  '/normalized/val/male/3021123_21015_0_0.png',\n",
       "  '/normalized/val/male/1746642_21015_0_0.png',\n",
       "  '/normalized/val/male/2314590_21015_0_0.png',\n",
       "  '/normalized/val/male/5554364_21015_0_0.png',\n",
       "  '/normalized/val/male/5813240_21016_0_0.png',\n",
       "  '/normalized/val/male/1426047_21016_1_0.png',\n",
       "  '/normalized/val/male/3288488_21016_0_0.png',\n",
       "  '/normalized/val/male/4150462_21016_0_0.png',\n",
       "  '/normalized/val/male/2693646_21016_0_0.png',\n",
       "  '/normalized/val/male/2349638_21015_0_0.png',\n",
       "  '/normalized/val/male/3632694_21015_0_0.png',\n",
       "  '/normalized/val/male/1063967_21016_0_0.png',\n",
       "  '/normalized/val/male/1725422_21016_1_0.png',\n",
       "  '/normalized/val/male/3400615_21015_0_0.png',\n",
       "  '/normalized/val/male/1027734_21016_0_0.png',\n",
       "  '/normalized/val/male/1737707_21015_0_0.png',\n",
       "  '/normalized/val/male/4110072_21016_0_0.png',\n",
       "  '/normalized/val/male/4455258_21015_1_0.png',\n",
       "  '/normalized/val/male/2110573_21016_0_0.png',\n",
       "  '/normalized/val/male/4665521_21015_0_0.png',\n",
       "  '/normalized/val/male/2563966_21015_0_0.png',\n",
       "  '/normalized/val/male/5159526_21016_1_0.png',\n",
       "  '/normalized/val/male/5366032_21016_0_0.png',\n",
       "  '/normalized/val/male/3721377_21016_1_0.png',\n",
       "  '/normalized/val/male/5510006_21016_0_0.png',\n",
       "  '/normalized/val/male/2404019_21015_0_0.png',\n",
       "  '/normalized/val/male/5103599_21016_0_0.png'],\n",
       " ['/normalized/val/female/1241905_21015_0_0.png',\n",
       "  '/normalized/val/female/4515785_21016_0_0.png',\n",
       "  '/normalized/val/female/3438694_21016_0_0.png',\n",
       "  '/normalized/val/female/1872652_21016_0_0.png',\n",
       "  '/normalized/val/female/4061784_21016_0_0.png',\n",
       "  '/normalized/val/female/3672057_21016_0_0.png',\n",
       "  '/normalized/val/female/5879875_21016_0_0.png',\n",
       "  '/normalized/val/female/4953313_21015_0_0.png',\n",
       "  '/normalized/val/female/5772512_21015_0_0.png',\n",
       "  '/normalized/val/female/5156968_21016_1_0.png',\n",
       "  '/normalized/val/female/2460792_21016_0_0.png',\n",
       "  '/normalized/val/female/3970906_21016_0_0.png',\n",
       "  '/normalized/val/female/2797150_21016_0_0.png',\n",
       "  '/normalized/val/female/1773248_21015_0_0.png',\n",
       "  '/normalized/val/female/1417716_21015_0_0.png',\n",
       "  '/normalized/val/female/4035174_21016_0_0.png',\n",
       "  '/normalized/val/female/2714228_21016_0_0.png',\n",
       "  '/normalized/val/female/2848438_21016_0_0.png',\n",
       "  '/normalized/val/female/2376278_21015_0_0.png',\n",
       "  '/normalized/val/female/4119927_21016_0_0.png',\n",
       "  '/normalized/val/female/4736935_21016_0_0.png',\n",
       "  '/normalized/val/female/5317409_21015_0_0.png',\n",
       "  '/normalized/val/female/2962450_21016_0_0.png',\n",
       "  '/normalized/val/female/4795348_21016_0_0.png',\n",
       "  '/normalized/val/female/1460670_21016_0_0.png',\n",
       "  '/normalized/val/female/3132799_21016_0_0.png',\n",
       "  '/normalized/val/female/3456274_21015_0_0.png',\n",
       "  '/normalized/val/female/3436704_21016_1_0.png',\n",
       "  '/normalized/val/female/3637680_21015_0_0.png',\n",
       "  '/normalized/val/female/3751528_21016_0_0.png',\n",
       "  '/normalized/val/female/1331030_21015_1_0.png',\n",
       "  '/normalized/val/female/4953313_21016_0_0.png',\n",
       "  '/normalized/val/female/5282434_21015_0_0.png',\n",
       "  '/normalized/val/female/4061784_21015_0_0.png',\n",
       "  '/normalized/val/female/3074849_21016_0_0.png',\n",
       "  '/normalized/val/female/3158670_21016_0_0.png',\n",
       "  '/normalized/val/female/5772512_21016_0_0.png',\n",
       "  '/normalized/val/female/2140675_21015_0_0.png',\n",
       "  '/normalized/val/female/5640939_21016_0_0.png',\n",
       "  '/normalized/val/female/5419742_21016_0_0.png',\n",
       "  '/normalized/val/female/2893560_21016_0_0.png',\n",
       "  '/normalized/val/female/4030261_21016_0_0.png',\n",
       "  '/normalized/val/female/4473772_21016_1_0.png',\n",
       "  '/normalized/val/female/3599946_21016_0_0.png',\n",
       "  '/normalized/val/female/5050123_21016_0_0.png',\n",
       "  '/normalized/val/female/5464012_21016_0_0.png',\n",
       "  '/normalized/val/female/2247365_21015_0_0.png',\n",
       "  '/normalized/val/female/4022945_21016_0_0.png',\n",
       "  '/normalized/val/female/5419742_21015_0_0.png',\n",
       "  '/normalized/val/female/4789272_21016_0_0.png'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male = []\n",
    "female = []\n",
    "\n",
    "for _, _, _, path in top_f:\n",
    "    female.append(path)\n",
    "for _, _, _, path in top_m:        \n",
    "    male.append(path)\n",
    "        \n",
    "male, female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFolder = \"D:/daten/normalized_val_UKBiobank\"\n",
    "targetFolder = \"C:/Users/dieck/Desktop/highscore_pictures/\"\n",
    "\n",
    "for i, m in enumerate(male):\n",
    "    copyfile((sourceFolder + m), (targetFolder + \"male/male_rank_{}.png\".format(i)))\n",
    "\n",
    "for i, f in enumerate(female):\n",
    "    copyfile((sourceFolder + f), (targetFolder + \"female/female_rank_{}.png\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
